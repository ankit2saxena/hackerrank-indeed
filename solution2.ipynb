{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "import regex as re\n",
    "\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#read train.tsv using pandas\n",
    "train_data_file = pd.read_csv(\"train.tsv\", sep = \"\\t\")\n",
    "test_data_file = pd.read_csv(\"test.tsv\", sep = \"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "expected_tags = pd.DataFrame(['part-time-job',\n",
    "                             'full-time-job',\n",
    "                             'hourly-wage',\n",
    "                             'salary',\n",
    "                             'associate-needed',\n",
    "                             'bs-degree-needed',\n",
    "                             'ms-or-phd-needed',\n",
    "                             'licence-needed',\n",
    "                             '1-year-experience-needed',\n",
    "                             '2-4-years-experience-needed',\n",
    "                             '5-plus-years-experience-needed',\n",
    "                             'supervising-job'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "expected_tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_data_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To remove rows with NaN values in column \"tags\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data_file = train_data_file[train_data_file['tags'].isnull() == False]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To calculate number of rows and columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_rows = len(train_data_file.axes[0])\n",
    "train_cols = len(train_data_file.axes[1])\n",
    "\n",
    "test_rows = len(test_data_file.axes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To update the index numbers of the rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data_file.index = range(0, train_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To decode column \"description\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data_file['description'] = train_data_file['description'].map(lambda x: x.decode(\"utf8\").encode(\"ascii\",\"ignore\"))\n",
    "\n",
    "test_data_file['description'] = test_data_file['description'].map(lambda x: x.decode(\"utf8\").encode(\"ascii\",\"ignore\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To update column 'description' based on word boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data_file['description'] = train_data_file['description'].map(lambda x: re.sub(\"\\W+\", ' ', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data_file['description'] = test_data_file['description'].map(lambda x: re.sub(\"\\W+\", ' ', x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To remove stop words from the column 'description'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data_file['description'] = train_data_file['description'].map(lambda x: ' '.join([word for word in x.split() if word not in (stopwords.words('english'))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data_file['description'] = test_data_file['description'].map(lambda x: ' '.join([word for word in x.split() if word not in (stopwords.words('english'))]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To convert the column 'description' to lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data_file['description'] = train_data_file['description'].map(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data_file['description'] = test_data_file['description'].map(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To create mapping of tags to description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_mapping(tag_key, train):\n",
    "    train_mapping = []\n",
    "    \n",
    "    for index, row in train.iterrows():\n",
    "        if tag_key in row.tags:\n",
    "            train_mapping.append(1)\n",
    "        else:\n",
    "            train_mapping.append(0)\n",
    "            \n",
    "    return train_mapping\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To create stem tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ss_tokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.wns = SnowballStemmer('english')\n",
    "    def __call__(self, value):\n",
    "        return [self.wns.stem(x) for x in word_tokenize(value)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def xgb_classifier(tag_key, train_text, tag_train_mapping, test_text):\n",
    "    \n",
    "    count_vect = CountVectorizer(tokenizer = ss_tokenizer(), ngram_range = (1,4))\n",
    "    X_train_counts = count_vect.fit_transform(train_text)\n",
    "\n",
    "    tfidf_transformer = TfidfTransformer()\n",
    "    X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "    \n",
    "    clf = xgb.XGBClassifier()\n",
    "\n",
    "    param_grid = {\n",
    "        'n_estimators': [100,150,200],\n",
    "    }\n",
    "\n",
    "    model = GridSearchCV(estimator=clf, param_grid=param_grid, n_jobs=2, verbose=20, scoring = 'f1_micro')\n",
    "\n",
    "    model.fit(X_train_tfidf, tag_train_mapping)    \n",
    "\n",
    "    X_new_counts = count_vect.transform(test_text)\n",
    "    X_new_tfidf = tfidf_transformer.transform(X_new_counts)\n",
    "    \n",
    "    predicted = model.predict(X_new_tfidf)\n",
    "    \n",
    "    print sum(predicted), tag_key\n",
    "        \n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# parent method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def solution1_1(classifier):\n",
    "    para_tags = [\" \"] * test_rows\n",
    "    for i in range(len(expected_tags)):\n",
    "        tag = expected_tags.iloc[i,0]\n",
    "        tag_train_mapping = create_mapping(tag, train_data_file)\n",
    "        output = classifier(tag, train_data_file['description'], tag_train_mapping, test_data_file['description'])\n",
    "        \n",
    "        for index, item in enumerate(output):\n",
    "            if item == 1:\n",
    "                if para_tags[index] == \" \":\n",
    "                    para_tags[index] = tag\n",
    "                else:\n",
    "                    para_tags[index] += \" \" + tag\n",
    "    \n",
    "    return para_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "run2 = solution1_1(xgb_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "run2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
